{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4849f9a",
   "metadata": {},
   "source": [
    "# Snore Detection from Audio â€” Jupyter Notebook\n",
    "\n",
    "This notebook shows an end-to-end pipeline for building a snore detection classifier from audio files.\n",
    "It extracts features (mel-spectrograms) and trains a small CNN using TensorFlow / Keras.\n",
    "\n",
    "**Important:** Adjust the labeling logic inside the notebook if your dataset uses different filenames or a CSV for labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if necessary\n",
    "!pip install --quiet librosa soundfile tensorflow scikit-learn matplotlib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: extract archive.zip if present\n",
    "import os, zipfile\n",
    "ARCHIVE='/mnt/data/archive.zip'\n",
    "EXTRACT_DIR='/mnt/data/extracted_audio'\n",
    "if os.path.exists(ARCHIVE):\n",
    "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "    with zipfile.ZipFile(ARCHIVE,'r') as z:\n",
    "        z.extractall(EXTRACT_DIR)\n",
    "    print('Extracted to', EXTRACT_DIR)\n",
    "else:\n",
    "    print('No archive found at', ARCHIVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect audio files\n",
    "from glob import glob\n",
    "audio_paths = glob('/mnt/data/extracted_audio/**', recursive=True)\n",
    "audio_paths = [p for p in audio_paths if p.lower().endswith(('.wav','.flac','.mp3','.m4a','.ogg'))]\n",
    "print('Found', len(audio_paths), 'audio files')\n",
    "for p in audio_paths[:10]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5646a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple heuristic labeling function - edit if needed\n",
    "def get_label_from_path(path):\n",
    "    n = os.path.basename(path).lower()\n",
    "    if 'snore' in n or 'snores' in n or 'snoring' in n:\n",
    "        return 1\n",
    "    lower = path.lower()\n",
    "    if '/snore/' in lower or '\\\\snore\\\\' in lower:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# quick distribution\n",
    "labels = [get_label_from_path(p) for p in audio_paths]\n",
    "from collections import Counter\n",
    "print('Label counts (heuristic):', Counter(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0359696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction (mel spectrograms)\n",
    "import librosa, numpy as np\n",
    "from tqdm import tqdm\n",
    "SR=22050\n",
    "DURATION=4.0\n",
    "SAMPLES=int(SR*DURATION)\n",
    "N_MELS=64\n",
    "HOP_LENGTH=512\n",
    "\n",
    "def load_audio(path):\n",
    "    x,_ = librosa.load(path,sr=SR,mono=True,duration=DURATION)\n",
    "    if len(x) < SAMPLES:\n",
    "        x = np.pad(x,(0,SAMPLES-len(x)))\n",
    "    else:\n",
    "        x = x[:SAMPLES]\n",
    "    return x\n",
    "\n",
    "def extract_mel(path):\n",
    "    x = load_audio(path)\n",
    "    mel = librosa.feature.melspectrogram(y=x, sr=SR, n_mels=N_MELS, hop_length=HOP_LENGTH)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel_db = (mel_db - mel_db.mean())/(mel_db.std()+1e-6)\n",
    "    return mel_db.astype(np.float32)\n",
    "\n",
    "X_list=[]\n",
    "y_list=[]\n",
    "for p in tqdm(audio_paths):\n",
    "    try:\n",
    "        X_list.append(extract_mel(p))\n",
    "        y_list.append(get_label_from_path(p))\n",
    "    except Exception as e:\n",
    "        print('skip',p,e)\n",
    "\n",
    "X = np.array(X_list)\n",
    "y = np.array(y_list)\n",
    "print('X',X.shape,'y',y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5afede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Keras\n",
    "X = X[..., np.newaxis]\n",
    "print('Input shape:', X.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y,test_size=0.30,random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp,y_temp,test_size=0.50,random_state=42, stratify=y_temp)\n",
    "print('Train',X_train.shape,'Val',X_val.shape,'Test',X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a small CNN (Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "input_shape = X_train.shape[1:]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(16,(3,3),activation='relu',padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu',padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy',tf.keras.metrics.AUC(name='auc')])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (adjust EPOCHS/BATCH_SIZE for your environment)\n",
    "EPOCHS=12\n",
    "BATCH_SIZE=16\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)]\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=EPOCHS,batch_size=BATCH_SIZE,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save\n",
    "res = model.evaluate(X_test,y_test)\n",
    "print('Test results:', res)\n",
    "model.save('/mnt/data/snore_detector_model.h5')\n",
    "print('Model saved to /mnt/data/snore_detector_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick predict helper\n",
    "from tensorflow.keras.models import load_model\n",
    "m = load_model('/mnt/data/snore_detector_model.h5')\n",
    "\n",
    "def predict_snore(path):\n",
    "    mel = extract_mel(path)\n",
    "    mel = mel[np.newaxis,...,np.newaxis]\n",
    "    p = m.predict(mel)[0,0]\n",
    "    return p\n",
    "\n",
    "if len(audio_paths)>0:\n",
    "    print(audio_paths[0],'->',predict_snore(audio_paths[0]))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
